trainer:
    accelerator: "gpu"
    max_epochs: 200
    overfit_batches: 0.0
    log_every_n_steps: 1
    num_sanity_val_steps: 0

data:
    target_sampling_rate: 16000
    use_preloaded_data: true

    dynamic_loading:
        base_dir_data:
        train_metadata_path:
        val_metadata_path:
        test_metadata_path:
        filename_column:

    preloaded_loading:
        dataset:
            train_preloaded_path: "../../data/ravdess_preloaded_whisper_pooled/train"
            val_preloaded_path: "../../data/ravdess_preloaded_whisper_pooled/val"
            test_preloaded_path: "../../data/ravdess_preloaded_whisper_pooled/test"
            label_column: "label"
            embedding_column: "embedding"

        dataset2:
            train_preloaded_path: "../../data/ravdess_preloaded_wav2vec2_pooled/train"
            val_preloaded_path: "../../data/ravdess_preloaded_wav2vec2_pooled/val"
            test_preloaded_path: "../../data/ravdess_preloaded_wav2vec2_pooled/test"
            label_column: "label"
            embedding_column: "embedding"

            file_path_column: "wav_file"
            concatanation_type: "time"

model:
    input_size: 1536
    output_size: 8
    dropout: 0.2
    output_dims: [1024]

training:
    model_architecture: "mlp"
    lr: 1e-3
    scheduler_patience: 5
    batch_size: 16
    num_workers: 10

model_checkpoint:
    mode: "min"
    save_last: true
    save_weights_only: true
    monitor: "val_loss"
    dirpath: "../checkpoints/whisper_wav2vec2_classification_actor"

early_stopping:
    verbose: true
    monitor: "val_loss"
    patience: 100

encoder_version:

logger:
    project_name: "whisper_wav2vec2_classification_concept"
    debug: false
